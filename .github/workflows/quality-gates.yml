# Quality Gates Framework Template - 4-Gate Validation System
# Extracted from RAGnostic implementation - Production-ready patterns
# Template Version: 1.0 - Configurable quality enforcement levels
# Customized for BSN Knowledge - Knowledge Base System

name: ğŸ›¡ï¸ Quality Gates Framework

on:
  push:
    branches: [ main, develop, feature/*, hotfix/* ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      quality_level:
        description: 'Quality enforcement level'
        required: false
        default: 'standard'
        type: choice
        options:
          - strict
          - standard
          - advisory
      skip_slow_checks:
        description: 'Skip slow quality checks'
        required: false
        default: false
        type: boolean

env:
  PROJECT_NAME: "bsn-knowledge"
  PROJECT_TYPE: "knowledge-base"
  PYTHON_VERSION: "3.12"
  UV_VERSION: "0.8.3"
  QUALITY_GATES_VERSION: "2.0"

# Cost optimization
concurrency:
  group: quality-gates-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  security-events: write
  pull-requests: write
  checks: write
  actions: read

jobs:
  # ============================================================================
  # QUALITY GATE 1: ENVIRONMENT & SETUP VALIDATION
  # ============================================================================
  gate-1-setup:
    name: 'Gate 1: Environment & Setup'
    runs-on: ubuntu-latest
    timeout-minutes: 8
    outputs:
      quality-level: ${{ steps.config.outputs.quality-level }}
      cache-key: ${{ steps.setup.outputs.cache-key }}
      should-enforce: ${{ steps.config.outputs.should-enforce }}
      coverage-threshold: ${{ steps.config.outputs.coverage-threshold }}
    steps:
      - name: 'Checkout Repository'
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 'Setup Python & UV'
        id: setup
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true

      - name: 'Install Python'
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: 'Cache Dependencies'
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            .venv
          key: quality-gates-${{ runner.os }}-uv-${{ hashFiles('pyproject.toml', 'uv.lock') }}
          restore-keys: |
            quality-gates-${{ runner.os }}-uv-

      - name: 'Install Dependencies'
        run: |
          uv sync --all-extras --frozen
          echo "cache-key=quality-gates-${{ runner.os }}-uv-${{ hashFiles('pyproject.toml', 'uv.lock') }}" >> $GITHUB_OUTPUT

      - name: 'Configure Quality Gates'
        id: config
        run: |
          if [[ "${{ github.event.inputs.quality_level }}" == "strict" ]]; then
            echo "quality-level=strict" >> $GITHUB_OUTPUT
            echo "should-enforce=true" >> $GITHUB_OUTPUT
            echo "coverage-threshold=90" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event.inputs.quality_level }}" == "advisory" ]]; then
            echo "quality-level=advisory" >> $GITHUB_OUTPUT
            echo "should-enforce=false" >> $GITHUB_OUTPUT
            echo "coverage-threshold=70" >> $GITHUB_OUTPUT
          else
            echo "quality-level=standard" >> $GITHUB_OUTPUT
            echo "should-enforce=true" >> $GITHUB_OUTPUT
            echo "coverage-threshold=80" >> $GITHUB_OUTPUT
          fi

      - name: 'Validate Environment'
        run: |
          echo "ğŸ” Validating canonical environment..."
          if command -v make >/dev/null 2>&1; then
            make env-check
          else
            echo "âš ï¸ Makefile not found, performing basic validation"
            uv run python --version
            echo "âœ… Environment validated"
          fi
          
          echo "ğŸ“Š Quality Gates Environment Report:"
          echo "- Python: $(uv run python --version)"
          echo "- UV: $(uv --version)" 
          echo "- Quality Level: ${{ steps.config.outputs.quality-level }}"
          echo "- Enforcement: ${{ steps.config.outputs.should-enforce }}"
          echo "- Coverage Threshold: ${{ steps.config.outputs.coverage-threshold }}%"

  # ============================================================================
  # QUALITY GATE 2: CODE QUALITY & STANDARDS ENFORCEMENT
  # ============================================================================
  gate-2-code-quality:
    name: 'Gate 2: Code Quality & Standards'
    runs-on: ubuntu-latest
    needs: gate-1-setup
    timeout-minutes: 12
    steps:
      - name: 'Checkout Repository'
        uses: actions/checkout@v4

      - name: 'Setup Python & UV'
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}

      - name: 'Install Python'
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: 'Restore Dependencies'
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            .venv
          key: ${{ needs.gate-1-setup.outputs.cache-key }}

      - name: 'Install Dependencies'
        run: uv sync --all-extras --frozen

      - name: 'Code Formatting Validation (Ruff)'
        run: |
          echo "ğŸ¨ Checking code formatting..."
          if [[ "${{ needs.gate-1-setup.outputs.quality-level }}" == "strict" ]]; then
            uv run ruff format --check src/ tests/
          else
            uv run ruff format --check src/ tests/ || {
              echo "âš ï¸ Code formatting issues found - run 'ruff format' to fix"
            }
          fi

      - name: 'Linting Validation (Ruff Critical Issues)'
        run: |
          echo "ğŸ” Running critical linting checks..."
          uv run ruff check src/ tests/ \
            --select="E9,F,B,S" \
            --ignore="B008,S314,S324,B017" \
            --output-format=github

      - name: 'Advanced Linting (Full Ruff Analysis)'
        continue-on-error: ${{ needs.gate-1-setup.outputs.quality-level != 'strict' }}
        run: |
          echo "ğŸ” Running comprehensive linting analysis..."
          uv run ruff check src/ tests/ \
            --output-format=github \
            --exit-zero || exit_code=$?
          
          if [[ "${{ needs.gate-1-setup.outputs.quality-level }}" == "strict" && ${exit_code:-0} -ne 0 ]]; then
            exit 1
          fi

      - name: 'Type Checking (MyPy)'
        continue-on-error: ${{ needs.gate-1-setup.outputs.quality-level == 'advisory' }}
        run: |
          echo "ğŸ” Running static type analysis..."
          uv run mypy src/ tests/ \
            --ignore-missing-imports \
            --show-error-codes \
            --show-error-context || exit_code=$?
          
          if [[ "${{ needs.gate-1-setup.outputs.quality-level }}" == "strict" && ${exit_code:-0} -ne 0 ]]; then
            exit 1
          fi

  # ============================================================================
  # QUALITY GATE 3: SECURITY VALIDATION & COMPLIANCE
  # ============================================================================
  gate-3-security:
    name: 'Gate 3: Security & Compliance'
    runs-on: ubuntu-latest
    needs: gate-1-setup
    timeout-minutes: 15
    strategy:
      fail-fast: false
      matrix:
        security-check: [static-analysis, dependencies, secrets, compliance]
    steps:
      - name: 'Checkout Repository'
        uses: actions/checkout@v4

      - name: 'Setup Python & UV'
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}

      - name: 'Install Python'
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: 'Restore Dependencies'
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            .venv
          key: ${{ needs.gate-1-setup.outputs.cache-key }}

      - name: 'Install Dependencies'
        run: uv sync --all-extras --frozen

      # Static Application Security Testing (SAST)
      - name: 'SAST Analysis (Bandit)'
        if: matrix.security-check == 'static-analysis'
        run: |
          echo "ğŸ” Running static application security testing..."
          mkdir -p reports/security
          
          uv run bandit -r src/ tests/ \
            -f json -o reports/security/bandit-report.json \
            -f sarif -o reports/security/bandit-report.sarif || exit_code=$?
          
          if [[ -f "reports/security/bandit-report.json" ]]; then
            high_issues=$(jq '[.results[] | select(.issue_severity == "HIGH" or .issue_severity == "CRITICAL")] | length' reports/security/bandit-report.json)
            
            echo "ğŸ“Š Security Analysis Results: HIGH/CRITICAL: $high_issues"
            
            if [[ "${{ needs.gate-1-setup.outputs.should-enforce }}" == "true" && $high_issues -gt 0 ]]; then
              echo "ğŸš¨ SECURITY GATE FAILURE: $high_issues HIGH/CRITICAL issues found"
              exit 1
            fi
          fi

      # Dependency Vulnerability Scanning
      - name: 'Dependency Security (Safety)'
        if: matrix.security-check == 'dependencies'
        run: |
          echo "ğŸ›¡ï¸ Scanning dependency vulnerabilities..."
          mkdir -p reports/security
          
          uv export --format requirements-txt > requirements-export.txt
          uv run safety check --file requirements-export.txt \
            --json --output reports/security/safety-report.json || exit_code=$?
          
          if [[ -f "reports/security/safety-report.json" ]]; then
            vulnerabilities=$(jq '. | length' reports/security/safety-report.json 2>/dev/null || echo "0")
            
            if [[ $vulnerabilities -gt 0 ]]; then
              echo "ğŸš¨ Found $vulnerabilities dependency vulnerabilities"
              if [[ "${{ needs.gate-1-setup.outputs.should-enforce }}" == "true" ]]; then
                exit 1
              fi
            else
              echo "âœ… No known dependency vulnerabilities found"
            fi
          fi

      # Secrets Detection
      - name: 'Secrets Detection'
        if: matrix.security-check == 'secrets'
        run: |
          echo "ğŸ•µï¸ Detecting potential secrets..."
          pip install detect-secrets
          detect-secrets scan --all-files \
            --baseline .secrets.baseline \
            --exclude-files ".venv/.*|htmlcov/.*|\.git/.*" || exit_code=$?
          
          if [[ -f ".secrets.baseline" ]]; then
            secrets_count=$(jq '.results | to_entries | length' .secrets.baseline 2>/dev/null || echo "0")
            
            if [[ $secrets_count -gt 0 ]]; then
              echo "ğŸš¨ Potential secrets detected: $secrets_count"
              if [[ "${{ needs.gate-1-setup.outputs.should-enforce }}" == "true" ]]; then
                echo "Review and whitelist legitimate secrets in .secrets.baseline"
                exit 1
              fi
            else
              echo "âœ… No secrets detected"
            fi
          fi

      # Knowledge Base Compliance Validation
      - name: 'Knowledge Base Compliance Validation'
        if: matrix.security-check == 'compliance'
        run: |
          echo "ğŸ“‹ Running knowledge base compliance validation..."
          mkdir -p reports/security
          
          # Check for knowledge base documentation
          missing_docs=0
          for component in api search indexing content; do
            if [ ! -f "docs/${component}_documentation.md" ] && [ ! -f "README.md" ]; then
              ((missing_docs++))
            fi
          done
          
          echo "ğŸ“Š Documentation compliance: $missing_docs components missing docs"
          
          # Check for proper API documentation
          if [ ! -f "docs/API_DOCUMENTATION.md" ] && [ ! -f "README.md" ]; then
            echo "âš ï¸ Missing API documentation"
          fi
          
          # License compliance check
          missing_licenses=0
          for file in $(find src/ -name "*.py" | head -20); do
            if ! grep -q "license\|License\|LICENSE" "$file"; then
              ((missing_licenses++))
            fi
          done
          
          echo "ğŸ“Š License compliance: $missing_licenses files missing headers"
          
          if [[ "${{ needs.gate-1-setup.outputs.quality-level }}" == "strict" && $missing_licenses -gt 10 ]]; then
            echo "ğŸš¨ COMPLIANCE FAILURE: Too many files missing license headers"
            exit 1
          fi
          
          echo "âœ… Knowledge base compliance validation completed"

      - name: 'Upload Security Reports'
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-reports-${{ matrix.security-check }}
          path: |
            reports/security/
            .secrets.baseline
          retention-days: 30

      - name: 'Upload SARIF Results'
        if: always() && matrix.security-check == 'static-analysis'
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: reports/security/bandit-report.sarif
          category: quality-gates-security

  # ============================================================================
  # QUALITY GATE 4: TESTING & COVERAGE VALIDATION
  # ============================================================================
  gate-4-testing:
    name: 'Gate 4: Testing & Coverage'
    runs-on: ubuntu-latest
    needs: gate-1-setup
    timeout-minutes: 25

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: 'Checkout Repository'
        uses: actions/checkout@v4

      - name: 'Setup Python & UV'
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}

      - name: 'Install Python'
        run: uv python install ${{ env.PYTHON_VERSION }}

      - name: 'Restore Dependencies'
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            .venv
          key: ${{ needs.gate-1-setup.outputs.cache-key }}

      - name: 'Install Dependencies'
        run: uv sync --all-extras --frozen

      - name: 'Wait for Services'
        run: |
          echo "â³ Waiting for PostgreSQL and Redis..."
          timeout 60 bash -c 'until nc -z localhost 5432; do sleep 1; done'
          timeout 60 bash -c 'until nc -z localhost 6379; do sleep 1; done'

      - name: 'Setup Test Environment'
        run: |
          cp .env.test.template .env.test 2>/dev/null || touch .env.test
          echo "DATABASE_URL=postgresql://test_user:test_password@localhost:5432/test_db" >> .env.test
          echo "REDIS_URL=redis://localhost:6379/0" >> .env.test
          echo "TESTING=true" >> .env.test

      - name: 'Run Comprehensive Test Suite'
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
          TESTING: true
        run: |
          echo "ğŸ§ª Running comprehensive test suite..."
          mkdir -p reports/testing
          
          uv run pytest tests/ \
            --cov=src/ \
            --cov-report=xml:reports/testing/coverage.xml \
            --cov-report=html:reports/testing/htmlcov \
            --cov-report=term-missing \
            --cov-report=json:reports/testing/coverage.json \
            --cov-fail-under=${{ needs.gate-1-setup.outputs.coverage-threshold }} \
            --junit-xml=reports/testing/results.xml \
            -v

      - name: 'Upload Test Reports'
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-reports
          path: |
            reports/testing/
          retention-days: 30

      - name: 'Upload Coverage to Codecov'
        uses: codecov/codecov-action@v4
        with:
          file: ./reports/testing/coverage.xml
          flags: quality-gates
          name: quality-gates-coverage

  # ============================================================================
  # QUALITY GATES SUMMARY & REPORTING
  # ============================================================================
  quality-gates-summary:
    name: 'Quality Gates Summary'
    runs-on: ubuntu-latest
    needs: [gate-1-setup, gate-2-code-quality, gate-3-security, gate-4-testing]
    if: always()
    timeout-minutes: 5
    steps:
      - name: 'Generate Quality Gates Report'
        run: |
          echo "# ğŸ›¡ï¸ BSN Knowledge Quality Gates Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ğŸ“Š Quality Gates Results" >> $GITHUB_STEP_SUMMARY
          echo "| Gate | Result | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|------|--------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Gate 1: Setup | ${{ needs.gate-1-setup.result == 'success' && 'âœ…' || 'âŒ' }} | Environment & Configuration |" >> $GITHUB_STEP_SUMMARY
          echo "| Gate 2: Code Quality | ${{ needs.gate-2-code-quality.result == 'success' && 'âœ…' || 'âŒ' }} | Formatting, Linting, Type Checking |" >> $GITHUB_STEP_SUMMARY
          echo "| Gate 3: Security | ${{ needs.gate-3-security.result == 'success' && 'âœ…' || 'âŒ' }} | SAST, Dependencies, Secrets, Compliance |" >> $GITHUB_STEP_SUMMARY
          echo "| Gate 4: Testing | ${{ needs.gate-4-testing.result == 'success' && 'âœ…' || 'âŒ' }} | Unit, Integration, Coverage |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## âš™ï¸ Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Quality Level**: ${{ needs.gate-1-setup.outputs.quality-level }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Enforcement**: ${{ needs.gate-1-setup.outputs.should-enforce }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Coverage Threshold**: ${{ needs.gate-1-setup.outputs.coverage-threshold }}%" >> $GITHUB_STEP_SUMMARY
          echo "- **Knowledge Base Features**: Search validation, Content indexing, API testing" >> $GITHUB_STEP_SUMMARY

      - name: 'Quality Gates Enforcement Decision'
        run: |
          echo "ğŸšª Quality Gates Final Enforcement Decision..."
          
          setup_result="${{ needs.gate-1-setup.result }}"
          quality_result="${{ needs.gate-2-code-quality.result }}"
          security_result="${{ needs.gate-3-security.result }}"
          testing_result="${{ needs.gate-4-testing.result }}"
          
          echo "ğŸ“Š Gate Results:"
          echo "- Setup: $setup_result"
          echo "- Code Quality: $quality_result"
          echo "- Security: $security_result"
          echo "- Testing: $testing_result"
          
          if [[ "${{ needs.gate-1-setup.outputs.should-enforce }}" == "true" ]]; then
            failed_gates=()
            [[ "$setup_result" != "success" ]] && failed_gates+=("setup")
            [[ "$quality_result" != "success" ]] && failed_gates+=("code-quality")
            [[ "$security_result" != "success" ]] && failed_gates+=("security")
            [[ "$testing_result" != "success" ]] && failed_gates+=("testing")
            
            if [[ ${#failed_gates[@]} -gt 0 ]]; then
              echo "ğŸš¨ QUALITY GATES FAILURE"
              echo "Failed gates: ${failed_gates[*]}"
              exit 1
            else
              echo "âœ… ALL QUALITY GATES PASSED"
            fi
          else
            echo "â„¹ï¸ Quality gates in advisory mode"
          fi

      - name: 'Post Results to PR'
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const results = {
              setup: '${{ needs.gate-1-setup.result }}',
              quality: '${{ needs.gate-2-code-quality.result }}',
              security: '${{ needs.gate-3-security.result }}',
              testing: '${{ needs.gate-4-testing.result }}'
            };
            
            const passed = Object.values(results).filter(r => r === 'success').length;
            const total = Object.keys(results).length;
            
            const comment = `## ğŸ›¡ï¸ BSN Knowledge Quality Gates Report
            
            **Quality Level**: ${{ needs.gate-1-setup.outputs.quality-level }}
            **Results**: ${passed}/${total} gates passed
            
            | Gate | Result |
            |------|--------|
            | Setup & Environment | ${results.setup === 'success' ? 'âœ…' : 'âŒ'} |
            | Code Quality & Standards | ${results.quality === 'success' ? 'âœ…' : 'âŒ'} |
            | Security & Compliance | ${results.security === 'success' ? 'âœ…' : 'âŒ'} |
            | Testing & Coverage | ${results.testing === 'success' ? 'âœ…' : 'âŒ'} |
            
            **Knowledge Base Features Tested:**
            - ğŸ“š Search and retrieval validation
            - ğŸ” Content indexing patterns
            - ğŸŒ FastAPI endpoint testing
            - ğŸ’¾ PostgreSQL + Redis + Qdrant integration
            
            ${passed === total ? 'ğŸ‰ All quality gates passed! Ready for merge.' : 'âš ï¸ Some quality gates need attention before merge.'}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });